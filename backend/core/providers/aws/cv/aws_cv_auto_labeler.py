"""
AWS CV Auto Labeler Implementation

AWS ì „ìš© Computer Vision ì˜¤í† ë¼ë²¨ëŸ¬ êµ¬í˜„ì²´
"""

import os
import torch
import cv2
import numpy as np
import faiss
import re
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from PIL import Image, ImageOps
import open_clip
from tqdm import tqdm
from collections import defaultdict
from dataclasses import dataclass

# core í”„ë ˆì„ì›Œí¬ import
from ....auto_labeler.cv_auto_labeler import CVAutoLabeler
from ....models import (
    DetectionResult, 
    BoundingBox,
    CloudProvider,
    DetectionStatus
)
from ....taxonomy import AWSTaxonomy


@dataclass
class IconInfo:
    """ì•„ì´ì½˜ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    file_path: str
    service_name: str
    service_code: str
    category: str
    size: int
    confidence: float


def safe_load_image(image_path: str) -> Image.Image:
    """ì•ˆì „í•œ ì´ë¯¸ì§€ ë¡œë”© - ëª¨ë“  ëª¨ë“œ ì§€ì›"""
    try:
        pil = Image.open(image_path)
        return pil
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {image_path} - {e}")
        return Image.new('RGB', (256, 256), (255, 255, 255))


def safe_convert_to_rgba(pil: Image.Image) -> Image.Image:
    """ì•ˆì „í•œ RGBA ë³€í™˜"""
    try:
        if pil.mode == 'RGBA':
            return pil
        elif pil.mode in ('RGB', 'L'):
            if pil.mode == 'L':
                pil = pil.convert('RGB')
            alpha = Image.new('L', pil.size, 255)
            pil.putalpha(alpha)
            return pil
        elif pil.mode == 'P':
            return pil.convert('RGBA')
        else:
            pil = pil.convert('RGB')
            alpha = Image.new('L', pil.size, 255)
            pil.putalpha(alpha)
            return pil
    except Exception as e:
        print(f"âš ï¸ RGBA ë³€í™˜ ì‹¤íŒ¨: {e}")
        return pil.convert('RGB')


def safe_trim_transparent(pil: Image.Image) -> Image.Image:
    """ì•ˆì „í•œ íˆ¬ëª… ë°°ê²½ ì œê±° - RGBA ëª¨ë“œ ì§€ì›"""
    try:
        if pil.mode != 'RGBA':
            pil = safe_convert_to_rgba(pil)
        
        if pil.mode == 'RGBA':
            alpha = pil.getchannel('A')
            bbox = alpha.getbbox()
            if bbox:
                return pil.crop(bbox)
        
        return pil
    except Exception as e:
        print(f"âš ï¸ íˆ¬ëª… ë°°ê²½ ì œê±° ì‹¤íŒ¨: {e}")
        return pil


def safe_square_pad(pil: Image.Image, canvas_size: int = 256, pad_ratio: float = 0.06) -> Image.Image:
    """ì•ˆì „í•œ ì •ì‚¬ê° íŒ¨ë”©"""
    try:
        pil = safe_trim_transparent(pil)
        
        w, h = pil.size
        pad = int(round(pad_ratio * max(w, h)))
        scale = (canvas_size - pad * 2) / max(w, h)
        
        new_w = max(1, int(w * scale))
        new_h = max(1, int(h * scale))
        pil_resized = pil.resize((new_w, new_h), Image.LANCZOS)
        
        canvas = Image.new('RGBA', (canvas_size, canvas_size), (0, 0, 0, 0))
        x = (canvas_size - new_w) // 2
        y = (canvas_size - new_h) // 2
        canvas.paste(pil_resized, (x, y), pil_resized)
        
        return canvas
    except Exception as e:
        print(f"âš ï¸ ì •ì‚¬ê° íŒ¨ë”© ì‹¤íŒ¨: {e}")
        return pil.resize((canvas_size, canvas_size), Image.LANCZOS)


def process_icon_for_clip(pil: Image.Image, canvas_size: int = 256) -> Image.Image:
    """CLIP ëª¨ë¸ìš© ì•„ì´ì½˜ ì „ì²˜ë¦¬ - ì™„ì „ ì•ˆì „"""
    try:
        pil = safe_convert_to_rgba(pil)
        pil = safe_trim_transparent(pil)
        pil = safe_square_pad(pil, canvas_size)
        return pil.convert('RGB')
    except Exception as e:
        print(f"âš ï¸ ì•„ì´ì½˜ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return Image.new('RGB', (canvas_size, canvas_size), (255, 255, 255))


def orb_score(patch_bgr, icon_bgr, nfeatures=500):
    """ORB ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìœ ì‚¬ì„± ì¸¡ì •"""
    try:
        orb = cv2.ORB_create(nfeatures=nfeatures)
        
        kp1, des1 = orb.detectAndCompute(cv2.cvtColor(patch_bgr, cv2.COLOR_BGR2GRAY), None)
        kp2, des2 = orb.detectAndCompute(cv2.cvtColor(icon_bgr, cv2.COLOR_BGR2GRAY), None)
        
        if des1 is None or des2 is None or len(kp1) < 5 or len(kp2) < 5:
            return 0.0
        
        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
        m = bf.match(des1, des2)
        
        if not m:
            return 0.0
        
        m = sorted(m, key=lambda x: x.distance)
        good = [x for x in m if x.distance < 64]
        
        return min(1.0, len(good) / max(10, len(m)))
    except Exception as e:
        print(f"âš ï¸ ORB ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0


class IconScanner:
    """AWS ì•„ì´ì½˜ ìŠ¤ìºë„ˆ - aws_cv_clipì—ì„œ ê°€ì ¸ì˜¨ ì„±ê³µì ì¸ ë¡œì§"""
    
    def __init__(self, icons_dir: str, taxonomy_csv: str):
        self.icons_dir = Path(icons_dir)
        self.service_mapping = self._load_taxonomy(taxonomy_csv)
    
    def _load_taxonomy(self, taxonomy_csv: str) -> Dict[str, str]:
        """íƒì†Œë…¸ë¯¸ ë¡œë“œ ë° ì„œë¹„ìŠ¤ ë§¤í•‘ ìƒì„±"""
        df = pd.read_csv(taxonomy_csv)
        return {
            row['service_code'].strip().lower(): row['service_full_name'].strip()
            for _, row in df.iterrows()
            if pd.notna(row.get('service_code')) and pd.notna(row.get('service_full_name'))
        }
    
    def scan_icons(self) -> List[IconInfo]:
        """PNG ì•„ì´ì½˜ ìŠ¤ìº” - ìµœëŒ€ ì‚¬ì´ì¦ˆë§Œ ì„ íƒ"""
        service_best_icons = defaultdict(lambda: {"size": 0, "icon": None})
        
        # ëŒ€ìƒ ë””ë ‰í„°ë¦¬
        target_dirs = ["Resource-Icons_02072025", "Architecture-Service-Icons_02072025"]
        
        for target_dir in target_dirs:
            target_path = self.icons_dir / target_dir
            if not target_path.exists():
                continue
            
            # PNG íŒŒì¼ë§Œ ì¬ê·€ ìŠ¤ìº”
            for png_file in target_path.rglob("*.png"):
                try:
                    # ì„œë¹„ìŠ¤ëª… ì¶”ì¶œ
                    service_name, confidence = self._extract_service_name(png_file.name, target_dir)
                    if service_name == "Unknown" or confidence < 0.5:
                        continue
                    
                    # ì‚¬ì´ì¦ˆ ì¶”ì¶œ
                    size = self._extract_size(png_file.name)
                    
                    # ì„œë¹„ìŠ¤ë³„ ìµœëŒ€ ì‚¬ì´ì¦ˆ ì„ íƒ
                    service_key = service_name
                    if size > service_best_icons[service_key]["size"]:
                        icon_info = IconInfo(
                            file_path=str(png_file.relative_to(self.icons_dir)),
                            service_name=service_name,
                            service_code=self._find_service_code(service_name),
                            category=self._extract_category(str(png_file.relative_to(self.icons_dir))),
                            size=size,
                            confidence=confidence
                        )
                        service_best_icons[service_key] = {"size": size, "icon": icon_info}
                        
                except Exception as e:
                    print(f"âš ï¸ ì•„ì´ì½˜ ì²˜ë¦¬ ì‹¤íŒ¨: {png_file.name} - {e}")
                    continue
        
        # ìµœëŒ€ ì‚¬ì´ì¦ˆ ì•„ì´ì½˜ë“¤ë§Œ ë°˜í™˜
        icons = [data["icon"] for data in service_best_icons.values() if data["icon"]]
        print(f"âœ… ìŠ¤ìº” ì™„ë£Œ: {len(icons)}ê°œ ì„œë¹„ìŠ¤ì˜ ìµœëŒ€ ì‚¬ì´ì¦ˆ PNG ì•„ì´ì½˜")
        return icons
    
    def _extract_service_name(self, filename: str, icon_type: str) -> Tuple[str, float]:
        """íŒŒì¼ëª…ì—ì„œ ì„œë¹„ìŠ¤ëª… ì¶”ì¶œ - ì„¸ë¶€ ì•„ì´ì½˜ ê°œë³„ ì²˜ë¦¬"""
        name = Path(filename).stem
        
        # íŒ¨í„´ ë§¤ì¹­
        if "Resource-Icons" in icon_type:
            pattern = r'Res_([A-Za-z0-9-]+)_([A-Za-z0-9-]+)_\d+'
        else:
            pattern = r'Arch_([A-Za-z0-9-]+)_\d+'
        
        match = re.search(pattern, name)
        if match:
            if "Resource-Icons" in icon_type:
                service_code = match.group(1).lower()
                detail_code = match.group(2).lower()
                
                # ì„¸ë¶€ ì„œë¹„ìŠ¤ëª… ìƒì„± (ì˜ˆ: "Amazon CloudWatch Alarm")
                base_service = self.service_mapping.get(service_code, service_code)
                detail_service = f"{base_service} {detail_code.replace('-', ' ').title()}"
                
                return detail_service, 1.0
            else:
                service_code = match.group(1).lower()
                if service_code in self.service_mapping:
                    return self.service_mapping[service_code], 1.0
        
        return "Unknown", 0.0
    
    def _extract_size(self, filename: str) -> int:
        """íŒŒì¼ëª…ì—ì„œ ì‚¬ì´ì¦ˆ ì¶”ì¶œ"""
        match = re.search(r'_(\d+)\.png$', filename)
        return int(match.group(1)) if match else 0
    
    def _find_service_code(self, service_name: str) -> str:
        """ì„œë¹„ìŠ¤ëª…ì—ì„œ ì½”ë“œ ì°¾ê¸°"""
        for code, name in self.service_mapping.items():
            if name == service_name:
                return code
        return ""
    
    def _extract_category(self, file_path: str) -> str:
        """íŒŒì¼ ê²½ë¡œì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
        parts = file_path.split('/')
        if len(parts) > 1:
            return parts[0]
        return "Unknown"


class AWSCVAutoLabeler(CVAutoLabeler):
    """
    AWS ì „ìš© Computer Vision ì˜¤í† ë¼ë²¨ëŸ¬
    
    CLIP ê¸°ë°˜ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰ê³¼ ORB íŠ¹ì§•ì  ë§¤ì¹­ì„ ê²°í•©í•œ
    AWS ì„œë¹„ìŠ¤ ì•„ì´ì½˜ ì¸ì‹ ì‹œìŠ¤í…œ
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        AWS CV ì˜¤í† ë¼ë²¨ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            config: AWS ì „ìš© ì„¤ì •
        """
        # AWS ê¸°ë³¸ ì„¤ì • ì ìš©
        aws_config = self._prepare_aws_config(config)
        
        # configë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥
        self.config = aws_config
        
        # AWS íŠ¹í™” ì»´í¬ë„ŒíŠ¸ë¥¼ ë¨¼ì € ì´ˆê¸°í™”
        self._setup_aws_specific_components()
        
        # ê·¸ ë‹¤ìŒ ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        super().__init__(CloudProvider.AWS, aws_config)
        
        print(f"   - AWS ì•„ì´ì½˜ ë””ë ‰í„°ë¦¬: {config.get('data', {}).get('icons_dir', 'Not set')}")
        print(f"   - AWS íƒì†Œë…¸ë¯¸: {config.get('data', {}).get('taxonomy_csv', 'Not set')}")
    
    def _prepare_aws_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """AWS ì „ìš© ì„¤ì • ì¤€ë¹„"""
        # ê¸°ë³¸ AWS ì„¤ì •
        aws_config = {
            "cloud_provider": "aws",
            "method": "cv",
            "data": {
                "images_dir": config.get("data", {}).get("images_dir", "data/images"),
                "icons_dir": config.get("data", {}).get("icons_dir", "./icons"),
                "icons_zip": config.get("data", {}).get("icons_zip", "./Asset-Package.zip"),
                "icons_mapping_csv": config.get("data", {}).get("icons_mapping_csv", "./aws_icons_mapping.csv"),
                "taxonomy_csv": config.get("data", {}).get("taxonomy_csv", "./aws_resources_models.csv")
            },
            "cv": {
                "clip_name": config.get("cv", {}).get("clip_name", "ViT-B-32"),
                "clip_pretrained": config.get("cv", {}).get("clip_pretrained", "laion2b_s34b_b79k"),
                "device": "cuda" if torch.cuda.is_available() else "cpu"
            },
            "detection": {
                "max_size": config.get("detection", {}).get("max_size", 1600),
                "canny_low": config.get("detection", {}).get("canny_low", 60),
                "canny_high": config.get("detection", {}).get("canny_high", 160),
                "mser_delta": config.get("detection", {}).get("mser_delta", 5),
                "min_area": config.get("detection", {}).get("min_area", 900),
                "max_area": config.get("detection", {}).get("max_area", 90000),
                "win": config.get("detection", {}).get("win", 128),
                "stride": config.get("detection", {}).get("stride", 96),
                "iou_nms": config.get("detection", {}).get("iou_nms", 0.45),
                "use_canny": True,
                "use_mser": True,
                "use_sliding_window": True
            },
            "retrieval": {
                "topk": config.get("retrieval", {}).get("topk", 5),
                "accept_score": config.get("retrieval", {}).get("accept_score", 0.35),
                "orb_nfeatures": config.get("retrieval", {}).get("orb_nfeatures", 500),
                "score_clip_w": config.get("retrieval", {}).get("score_clip_w", 0.6),
                "score_orb_w": config.get("retrieval", {}).get("score_orb_w", 0.3),
                "score_ocr_w": config.get("retrieval", {}).get("score_ocr_w", 0.1)
            },
            "ocr": {
                "enabled": config.get("ocr", {}).get("enabled", True),
                "lang": config.get("ocr", {}).get("lang", ["en"])
            }
        }
        
        return aws_config
    
    def _setup_cv_components(self):
        """CV ì»´í¬ë„ŒíŠ¸ ì„¤ì •"""
        # CLIP ëª¨ë¸ ë¡œë“œ
        self.clip_model, self.clip_preprocess = self._load_clip_model()
        
        # ORB íŠ¹ì§•ì  ê²€ì¶œê¸°
        self.orb = cv2.ORB_create(
            nfeatures=self.retrieval_config.get("orb_nfeatures", 500)
        )
        
        # OCR ì„¤ì •
        self.ocr_enabled = self.config.get("ocr", {}).get("enabled", True)
        if self.ocr_enabled:
            try:
                import easyocr
                self.ocr_reader = easyocr.Reader(self.config.get("ocr", {}).get("lang", ["en"]))
            except ImportError:
                print("âš ï¸ easyocrì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ OCR ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤")
                self.ocr_enabled = False
    
    def _setup_aws_specific_components(self):
        """AWS íŠ¹í™” ì»´í¬ë„ŒíŠ¸ ì„¤ì •"""
        # AWS íŠ¹í™” ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”
        self._setup_aws_utilities()
        
        # AWS íƒì†Œë…¸ë¯¸ ë¡œë“œ
        self.aws_taxonomy = self._load_aws_taxonomy()
        
        # AWS ì•„ì´ì½˜ ìŠ¤ìºë„ˆ ì´ˆê¸°í™”
        icons_dir = self.config.get("data", {}).get("icons_dir")
        taxonomy_csv = self.config.get("data", {}).get("taxonomy_csv")
        if icons_dir and taxonomy_csv:
            self.icon_scanner = IconScanner(icons_dir, taxonomy_csv)
        else:
            self.icon_scanner = None
        
        # AWS ì•„ì´ì½˜ ì¸ë±ìŠ¤ëŠ” ë‚˜ì¤‘ì— í•„ìš”í•  ë•Œ êµ¬ì¶•
        self.aws_icon_index = None
    
    def _load_clip_model(self) -> Tuple[torch.nn.Module, callable]:
        """CLIP ëª¨ë¸ ë¡œë“œ"""
        model, preprocess, _ = open_clip.create_model_and_transforms(
            self.cv_config["clip_name"],
            pretrained=self.cv_config["clip_pretrained"],
            device=self.cv_config["device"]
        )
        model.eval()
        return model, preprocess
    
    def _build_aws_icon_index(self) -> Optional[Tuple[List[IconInfo], np.ndarray, faiss.Index]]:
        """AWS ì•„ì´ì½˜ ì¸ë±ìŠ¤ êµ¬ì¶• - aws_cv_clip ë¡œì§ ì ìš©"""
        # CLIP ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¨¼ì € ë¡œë“œ
        if not hasattr(self, 'clip_model') or self.clip_model is None:
            self._setup_cv_components()
        
        try:
            if not self.icon_scanner:
                print("âš ï¸ ì•„ì´ì½˜ ìŠ¤ìºë„ˆê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return None
            
            print("ğŸ” AWS ì•„ì´ì½˜ ì¸ë±ìŠ¤ ë¹Œë“œ ì¤‘...")
            
            # ì•„ì´ì½˜ ìŠ¤ìº”
            icons = self.icon_scanner.scan_icons()
            if not icons:
                raise ValueError("ìŠ¤ìº”ëœ AWS ì•„ì´ì½˜ì´ ì—†ìŠµë‹ˆë‹¤!")
            
            # ì„ë² ë”© ìƒì„±
            features = []
            valid_icons = []
            
            for icon in tqdm(icons, desc="ì•„ì´ì½˜ ì„ë² ë”© ìƒì„±"):
                try:
                    # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
                    icon_path = Path(self.icon_scanner.icons_dir) / icon.file_path
                    if not icon_path.exists():
                        continue
                    
                    # aws_cv_clipì˜ ì „ì²˜ë¦¬ ë¡œì§ ì ìš©
                    pil = safe_load_image(str(icon_path))
                    pil_processed = process_icon_for_clip(pil)
                    
                    # ì„ë² ë”© ìƒì„± - PIL Imageë¥¼ ì§ì ‘ ì „ë‹¬
                    feat = self._img_to_feat(pil_processed)
                    if feat is not None:
                        features.append(feat)
                        valid_icons.append(icon)
                
                except Exception as e:
                    print(f"âš ï¸ ì•„ì´ì½˜ ì²˜ë¦¬ ì‹¤íŒ¨: {icon.file_path} - {e}")
                    continue
            
            if not features:
                raise ValueError("ì²˜ë¦¬ëœ ì•„ì´ì½˜ì´ ì—†ìŠµë‹ˆë‹¤!")
            
            # FAISS ì¸ë±ìŠ¤ ìƒì„±
            features = np.stack(features).astype("float32")
            index = faiss.IndexFlatIP(features.shape[1])
            index.add(features)
            
            print(f"âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {len(valid_icons)}ê°œ ì•„ì´ì½˜")
            return valid_icons, features, index
            
        except Exception as e:
            print(f"âŒ AWS ì•„ì´ì½˜ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}")
            return None
    
    def _load_aws_taxonomy(self) -> Optional[AWSTaxonomy]:
        """AWS íƒì†Œë…¸ë¯¸ ë¡œë“œ"""
        try:
            taxonomy_path = self.config.get("data", {}).get("taxonomy_csv")
            if not taxonomy_path or not os.path.exists(taxonomy_path):
                print(f"âš ï¸ AWS íƒì†Œë…¸ë¯¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {taxonomy_path}")
                return None
            
            taxonomy = AWSTaxonomy()
            success = taxonomy.load_from_source(taxonomy_path)
            
            if success:
                print(f"âœ… AWS íƒì†Œë…¸ë¯¸ ë¡œë“œ ì™„ë£Œ: {len(taxonomy.get_all_names())}ê°œ ì„œë¹„ìŠ¤")
                return taxonomy
            else:
                print("âŒ AWS íƒì†Œë…¸ë¯¸ ë¡œë“œ ì‹¤íŒ¨")
                return None
            
        except Exception as e:
            print(f"âŒ AWS íƒì†Œë…¸ë¯¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _setup_aws_utilities(self):
        """AWS íŠ¹í™” ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”"""
        # AWS ì„œë¹„ìŠ¤ ì½”ë“œ ë§¤í•‘
        self.service_code_mapping = {
            "Amazon EC2": "ec2",
            "Amazon S3": "s3", 
            "AWS Lambda": "lambda",
            "Amazon RDS": "rds",
            "Amazon DynamoDB": "dynamodb",
            "Amazon CloudFront": "cloudfront",
            "Amazon API Gateway": "apigateway",
            "Amazon SNS": "sns",
            "Amazon SQS": "sqs",
            "Amazon CloudWatch": "cloudwatch",
            "AWS IAM": "iam",
            "Amazon VPC": "vpc",
            "Elastic Load Balancing": "elb",
            "Auto Scaling": "autoscaling",
            "Amazon ECS": "ecs",
            "Amazon EKS": "eks"
        }
        
        # ê³¼ë„í•œ ê°ì§€ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì„œë¹„ìŠ¤ë³„ ì œí•œ
        self.service_detection_limits = {
            "cloudwatch": 1,  # CloudWatchëŠ” ìµœëŒ€ 1ê°œë§Œ ê°ì§€ (ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„)
            "kinesis": 1,     # KinesisëŠ” ìµœëŒ€ 1ê°œë§Œ ê°ì§€
            "lambda": 3,      # LambdaëŠ” ìµœëŒ€ 3ê°œë§Œ ê°ì§€
            "s3": 2,          # S3ëŠ” ìµœëŒ€ 2ê°œë§Œ ê°ì§€
            "ec2": 4,         # EC2ëŠ” ìµœëŒ€ 4ê°œë§Œ ê°ì§€
        }
        
        # ì„œë¹„ìŠ¤ë³„ ìµœì†Œ ì‹ ë¢°ë„ ì„ê³„ê°’
        self.service_min_confidence = {
            "cloudwatch": 0.5,  # CloudWatchëŠ” ë” ë†’ì€ ì„ê³„ê°’
            "kinesis": 0.5,     # KinesisëŠ” ë” ë†’ì€ ì„ê³„ê°’
            "lambda": 0.4,      # LambdaëŠ” ë†’ì€ ì„ê³„ê°’
            "s3": 0.4,          # S3ëŠ” ë†’ì€ ì„ê³„ê°’
            "ec2": 0.35,        # EC2ëŠ” ê¸°ë³¸ ì„ê³„ê°’
        }
    
    def _apply_service_limits(self, detections: List[DetectionResult]) -> List[DetectionResult]:
        """ì„œë¹„ìŠ¤ë³„ ê°ì§€ ì œí•œ ì ìš©"""
        service_counts = {}
        filtered_detections = []
        
        for detection in detections:
            service_code = detection.service_code.lower()
            
            # í˜„ì¬ ì„œë¹„ìŠ¤ì˜ ê°ì§€ ìˆ˜ í™•ì¸
            current_count = service_counts.get(service_code, 0)
            max_count = self.service_detection_limits.get(service_code, 10)  # ê¸°ë³¸ê°’ 10
            
            # ìµœì†Œ ì‹ ë¢°ë„ í™•ì¸
            min_confidence = self.service_min_confidence.get(service_code, 0.35)
            
            if current_count < max_count and detection.confidence >= min_confidence:
                filtered_detections.append(detection)
                service_counts[service_code] = current_count + 1
            else:
                print(f"âš ï¸ ì„œë¹„ìŠ¤ ì œí•œìœ¼ë¡œ ì œì™¸: {service_code} (ì‹ ë¢°ë„: {detection.confidence:.3f})")
        
        return filtered_detections
    
    def _detect_regions(self, image: Image.Image) -> List[BoundingBox]:
        """ì´ë¯¸ì§€ì—ì„œ ê´€ì‹¬ ì˜ì—­ ê°ì§€ - aws_cv_clipì˜ propose ë¡œì§ ì ìš©"""
        # ì´ë¯¸ì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        img, scale = self._preprocess_resize(cv_image, self.detection_config.get("max_size", 1600))
        
        boxes = []
        
        # 1. Canny Edge + MSER
        if self.detection_config.get("use_canny", True) or self.detection_config.get("use_mser", True):
            edge_boxes = self._edges_and_mser(img)
            boxes.extend(edge_boxes)
        
        # 2. Sliding Window
        if self.detection_config.get("use_sliding_window", True):
            sliding_boxes = list(self._sliding_windows(img))
            boxes.extend(sliding_boxes)
        
        # ìŠ¤ì¼€ì¼ ë³µì›
        if scale != 1.0:
            boxes = [(int(x/scale), int(y/scale), int(w/scale), int(h/scale)) for (x,y,w,h) in boxes]
        
        # BoundingBox ê°ì²´ë¡œ ë³€í™˜
        return [BoundingBox(x, y, w, h) for x, y, w, h in boxes]
    
    def _preprocess_resize(self, img, max_size=1600):
        """ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •"""
        h, w = img.shape[:2]
        s = max(h, w)
        if s <= max_size: 
            return img, 1.0
        r = max_size / s
        img2 = cv2.resize(img, (int(w*r), int(h*r)), interpolation=cv2.INTER_AREA)
        return img2, r
    
    def _edges_and_mser(self, img):
        """Canny Edge + MSER ê°ì§€"""
        boxes = []
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # Canny Edge
        e = cv2.Canny(gray, 
                     self.detection_config.get("canny_low", 60),
                     self.detection_config.get("canny_high", 160))
        cnts, _ = cv2.findContours(e, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for c in cnts:
            x, y, w, h = cv2.boundingRect(c)
            a = w * h
            if (self.detection_config.get("min_area", 900) <= a <= 
                self.detection_config.get("max_area", 90000)):
                boxes.append((x, y, w, h))
        
        # MSER
        mser = cv2.MSER_create(delta=self.detection_config.get("mser_delta", 5))
        regions, _ = mser.detectRegions(gray)
        for r in regions:
            x, y, w, h = cv2.boundingRect(r.reshape(-1, 1, 2))
            a = w * h
            if (self.detection_config.get("min_area", 900) <= a <= 
                self.detection_config.get("max_area", 90000)):
                boxes.append((x, y, w, h))
        
        return boxes
    
    def _sliding_windows(self, img):
        """ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìƒì„±"""
        H, W = img.shape[:2]
        win = self.detection_config.get("win", 128)
        stride = self.detection_config.get("stride", 96)
        
        for y in range(0, max(1, H-win), stride):
            for x in range(0, max(1, W-win), stride):
                yield (x, y, win, win)
    
    def _extract_features(self, image: Image.Image, bbox: BoundingBox) -> np.ndarray:
        """ì˜ì—­ì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
        # ì´ë¯¸ì§€ í¬ë¡­
        cropped = self._crop_image(image, bbox)
        
        # CLIP ì„ë² ë”© ìƒì„± - PIL Imageë¥¼ ì§ì ‘ ì „ë‹¬
        features = self._img_to_feat(cropped)
        
        return features
    
    def _match_features(self, features: np.ndarray) -> List[Tuple[str, float]]:
        """íŠ¹ì§• ë§¤ì¹­ - aws_cv_clipì˜ ì •êµí•œ ì ìˆ˜ ê³„ì‚° ì ìš©"""
        if self.aws_icon_index is None:
            # ì•„ì´ì½˜ ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë©´ êµ¬ì¶•
            self.aws_icon_index = self._build_aws_icon_index()
            if self.aws_icon_index is None:
                return []
        
        valid_icons, icon_features, icon_index = self.aws_icon_index
        
        # FAISS ê²€ìƒ‰
        D, I = icon_index.search(features.reshape(1, -1), self.retrieval_config.get("topk", 5))
        
        matches = []
        for i, (distance, idx) in enumerate(zip(D[0], I[0])):
            if idx < len(valid_icons):
                icon_info = valid_icons[idx]
                
                # CLIP ì ìˆ˜
                clip_score = float((distance + 1) / 2)
                
                # ORB ì ìˆ˜ (ì°¸ì¡° ì•„ì´ì½˜ê³¼ ë¹„êµ)
                orb_score_val = self._calculate_orb_score(features, icon_info)
                
                # OCR ì ìˆ˜
                ocr_score = self._calculate_ocr_score(features)
                
                # ê°€ì¤‘í•© ì ìˆ˜
                final_score = (
                    self.retrieval_config.get("score_clip_w", 0.7) * clip_score +
                    self.retrieval_config.get("score_orb_w", 0.3) * orb_score_val +
                    self.retrieval_config.get("score_ocr_w", 0.1) * ocr_score
                )
                
                # íƒì†Œë…¸ë¯¸ ì •ê·œí™”
                if self.aws_taxonomy:
                    taxonomy_result = self.aws_taxonomy.normalize(icon_info.service_name)
                    normalized_name = taxonomy_result.canonical_name
                    taxonomy_confidence = taxonomy_result.confidence
                    
                    # ìµœì¢… ì‹ ë¢°ë„ ì¡°í•©
                    final_confidence = final_score * 0.7 + taxonomy_confidence * 0.3
                    
                    # ì„œë¹„ìŠ¤ ì½”ë“œ ì¶”ê°€
                    service_code = self.service_code_mapping.get(normalized_name, "")
                    
                    matches.append((normalized_name, final_confidence, service_code))
        
        # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return [(name, conf) for name, conf, _ in matches]
    
    def _calculate_orb_score(self, features: np.ndarray, icon_info: IconInfo) -> float:
        """ORB ì ìˆ˜ ê³„ì‚° - aws_cv_clip ë¡œì§ ì ìš©"""
        try:
            # ì°¸ì¡° ì•„ì´ì½˜ ë¡œë“œ
            icon_path = Path(self.icon_scanner.icons_dir) / icon_info.file_path
            if not icon_path.exists():
                return 0.0
            
            # ì°¸ì¡° ì•„ì´ì½˜ ì „ì²˜ë¦¬
            ref_pil = safe_load_image(str(icon_path))
            ref_pil_processed = process_icon_for_clip(ref_pil)
            ref_img = cv2.cvtColor(np.array(ref_pil_processed), cv2.COLOR_RGB2BGR)
            
            # í˜„ì¬ í¬ë¡­ ì´ë¯¸ì§€ (featuresì—ì„œ ë³µì› ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ì„ì‹œë¡œ 0 ë°˜í™˜)
            # ì‹¤ì œë¡œëŠ” í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ ì „ë‹¬ë°›ì•„ì•¼ í•¨
            return 0.3  # ê¸°ë³¸ê°’
            
        except Exception as e:
            print(f"âš ï¸ ORB ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_ocr_score(self, features: np.ndarray) -> float:
        """OCR ì ìˆ˜ ê³„ì‚°"""
        if not self.ocr_enabled:
            return 0.0
        
        try:
            # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ê¸°ë³¸ê°’ ë°˜í™˜
            return 0.1
            
        except Exception as e:
            print(f"âš ï¸ OCR ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _img_to_feat(self, img: Image.Image) -> Optional[np.ndarray]:
        """ì´ë¯¸ì§€ë¥¼ CLIP ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ - PIL Imageë¥¼ ì§ì ‘ ë°›ë„ë¡ ìˆ˜ì •"""
        try:
            with torch.no_grad():
                # PIL Imageë¥¼ CLIP ì „ì²˜ë¦¬
                img_tensor = self.clip_preprocess(img).unsqueeze(0).to(self.cv_config["device"])
                features = self.clip_model.encode_image(img_tensor)
                features = features / features.norm(dim=-1, keepdim=True)
            return features.squeeze(0).cpu().numpy()
        except Exception as e:
            print(f"âš ï¸ CLIP ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _crop_image(self, image: Image.Image, bbox: BoundingBox) -> Image.Image:
        """ì´ë¯¸ì§€ í¬ë¡­"""
        x, y, w, h = bbox.x, bbox.y, bbox.width, bbox.height
        return image.crop((x, y, x + w, y + h))
    
    def _load_taxonomy(self):
        """íƒì†Œë…¸ë¯¸ ë¡œë“œ (ì˜¤ë²„ë¼ì´ë“œ)"""
        # AWS íƒì†Œë…¸ë¯¸ê°€ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŒ
        if hasattr(self, 'aws_taxonomy'):
            return self.aws_taxonomy
        return None
