"""
AWS LLM Auto Labeler í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

from pathlib import Path

from ...providers.aws.llm import AWSLLMAutoLabeler


def test_aws_llm_auto_labeler():
    """AWS LLM Auto Labeler í…ŒìŠ¤íŠ¸"""
    print("ï¿½ï¿½ AWS LLM Auto Labeler í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ì„¤ì •
    config = {
        "data": {
            "taxonomy_csv": "data/aws/taxonomy/aws_resources_models.csv"
        },
        "llm": {
            "provider": "openai",  # ë˜ëŠ” "deepseek", "anthropic", "local"
            "base_url": "https://api.openai.com/v1",
            "api_key": "${OPENAI_API_KEY}",  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
            "vision_model": "gpt-4-vision-preview"
        },
        "prompt": {
            "system_prompt": "You are a precise AWS service recognizer.",
            "user_prompt_template": "Identify AWS services in this diagram."
        },
        "runtime": {
            "mode": "full_image",  # "full_image", "patch", "hybrid"
            "conf_threshold": 0.5,
            "patch_size": 512,
            "patch_stride": 256,
            "max_tokens": 2000,
            "temperature": 0.0
        }
    }
    
    try:
        # ì˜¤í† ë¼ë²¨ëŸ¬ ìƒì„±
        labeler = AWSLLMAutoLabeler(config)
        
        # í†µê³„ í™•ì¸
        stats = labeler.get_aws_llm_statistics()
        print(f"ï¿½ï¿½ LLM í†µê³„: {stats}")
        
        # ì§€ì› ë°ì´í„° íƒ€ì… í™•ì¸
        supported_types = labeler.get_supported_data_types()
        print(f"ğŸ“‹ ì§€ì› ë°ì´í„° íƒ€ì…: {supported_types}")
        
        # ì„¤ì • ê²€ì¦
        is_valid, errors = labeler.validate_config()
        if is_valid:
            print("âœ… ì„¤ì • ê²€ì¦ í†µê³¼")
        else:
            print(f"âŒ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨: {errors}")
        
        print("âœ… AWS LLM Auto Labeler í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    test_aws_llm_auto_labeler()
