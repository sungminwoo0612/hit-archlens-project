"""
Base Auto Labeler Module

í´ë¼ìš°ë“œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ìë™ ë¼ë²¨ë§ì„ ìœ„í•œ ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤
"""

import time
from abc import ABC, abstractmethod
from pathlib import Path
from typing import List, Dict, Any, Optional, Union, Tuple
from PIL import Image
from concurrent.futures import ThreadPoolExecutor, as_completed # ThreadPoolExecutor ì„í¬íŠ¸
from tqdm import tqdm

from ..models import (
    DetectionResult, 
    AnalysisResult, 
    BatchAnalysisResult,
    CloudProvider,
    AnalysisMethod,
    BoundingBox
)


class BaseAutoLabeler(ABC):
    """
    í´ë¼ìš°ë“œ ì¤‘ë¦½ ì˜¤í† ë¼ë²¨ëŸ¬ ê¸°ë³¸ í´ë˜ìŠ¤
    
    ëª¨ë“  í´ë¼ìš°ë“œ ì œê³µìë³„ ì˜¤í† ë¼ë²¨ëŸ¬ê°€ ìƒì†ë°›ì•„ì•¼ í•˜ëŠ” ê¸°ë³¸ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    
    def __init__(self, cloud_provider: Union[CloudProvider, str], config: Dict[str, Any]):
        """
        ê¸°ë³¸ ì˜¤í† ë¼ë²¨ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            cloud_provider: í´ë¼ìš°ë“œ ì œê³µì (aws, gcp, azure, naver)
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.cloud_provider = CloudProvider(cloud_provider) if isinstance(cloud_provider, str) else cloud_provider
        self.config = config
        self.taxonomy = self._load_taxonomy()
        
        # ì´ˆê¸°í™” ë¡œê·¸
        print(f"âœ… {self.cloud_provider.value.upper()} ì˜¤í† ë¼ë²¨ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - ì œê³µì: {self.cloud_provider.value}")
        print(f"   - ë°©ë²•: {self.get_method_name()}")
    
    @abstractmethod
    def get_method_name(self) -> str:
        """ë¶„ì„ ë°©ë²• ì´ë¦„ ë°˜í™˜ (cv, llm, hybrid)"""
        pass
    
    @abstractmethod
    def _load_taxonomy(self):
        """íƒì†Œë…¸ë¯¸ ë¡œë“œ (í´ë¼ìš°ë“œë³„ êµ¬í˜„)"""
        pass
    
    @abstractmethod
    def _analyze_single_image(self, image: Image.Image) -> List[DetectionResult]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„ (í´ë¼ìš°ë“œë³„ êµ¬í˜„)"""
        pass
    
    def analyze_image(self, image_path: Union[str, Path]) -> AnalysisResult:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì„œë¹„ìŠ¤ ì•„ì´ì½˜ì„ ê°ì§€í•˜ê³  ë¼ë²¨ë§í•©ë‹ˆë‹¤.
        
        Args:
            image_path: ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            AnalysisResult: ë¶„ì„ ê²°ê³¼
        """
        start_time = time.time()
        image_path = Path(image_path)
        
        if not image_path.exists():
            print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return AnalysisResult(
                image_path=image_path,
                width=0, height=0, detections=[], processing_time=0.0,
                cloud_provider=self.cloud_provider,
                analysis_method=self.get_method_name(),
                success=False, errors=[f"Image file not found: {image_path}"] # Set success to False
            )

        try:
            image = Image.open(image_path).convert("RGB")
            
            # ì‹¤ì œ ë¶„ì„ ë¡œì§
            detections = self._analyze_single_image(image)
            
            # íƒì†Œë…¸ë¯¸ ì •ê·œí™”
            normalized_detections = self._normalize_detections(detections)
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            print(f"âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ: {image_path.name} - {len(normalized_detections)}ê°œ ê°ì§€ ({processing_time:.2f}ì´ˆ)")
            
            return AnalysisResult(
                image_path=image_path,
                width=image.width,
                height=image.height,
                detections=normalized_detections,
                processing_time=processing_time,
                cloud_provider=self.cloud_provider,
                analysis_method=self.get_method_name(),
                success=True # Set success to True
            )
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {image_path.name} - {e}")
            return AnalysisResult(
                image_path=image_path,
                width=0, height=0, detections=[], processing_time=time.time() - start_time,
                cloud_provider=self.cloud_provider,
                analysis_method=self.get_method_name(),
                success=False, errors=[str(e)] # Set success to False and record error
            )

    def analyze_batch(self, image_paths: List[Union[str, Path]]) -> BatchAnalysisResult:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            image_paths: ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            BatchAnalysisResult: ë°°ì¹˜ ë¶„ì„ ê²°ê³¼
        """
        print(f"ğŸ“Š ë°°ì¹˜ ë¶„ì„ ì‹œì‘: {len(image_paths)}ê°œ ì´ë¯¸ì§€")
        total_start_time = time.time()
        
        all_results: List[AnalysisResult] = []
        total_detections = 0
        successful_images = 0
        failed_images = 0
        total_processing_time = 0.0
        batch_errors: List[Dict[str, Any]] = []

        # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
        max_workers = self.config.get("performance", {}).get("max_workers", 4)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_path = {executor.submit(self.analyze_image, path): path for path in image_paths}
            
            for future in tqdm(as_completed(future_to_path), total=len(image_paths), desc="ì´ë¯¸ì§€ ë¶„ì„"):
                image_path = future_to_path[future]
                try:
                    result = future.result()
                    all_results.append(result)
                    total_processing_time += result.processing_time
                    if result.success:
                        successful_images += 1
                        total_detections += result.detection_count
                    else:
                        failed_images += 1
                        batch_errors.append({"image_path": str(image_path), "message": result.errors[0] if result.errors else "Unknown error"})
                except Exception as e:
                    failed_images += 1
                    batch_errors.append({"image_path": str(image_path), "message": str(e)})
                    print(f"âŒ ë°°ì¹˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {image_path.name} - {e}")
        
        total_end_time = time.time()
        total_batch_processing_time = total_end_time - total_start_time
        
        print(f"âœ… ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {successful_images}ê°œ ì„±ê³µ, {failed_images}ê°œ ì‹¤íŒ¨ ({total_batch_processing_time:.2f}ì´ˆ)")
        
        return BatchAnalysisResult(
            results=all_results,
            total_images=len(image_paths),
            total_detections=total_detections,
            total_processing_time=total_processing_time, # Add total_processing_time
            average_processing_time=total_processing_time / successful_images if successful_images > 0 else 0.0,
            success_count=successful_images,
            error_count=failed_images,
            errors=batch_errors # Pass batch_errors here
        )
    
    def analyze_directory(self, directory_path: Union[str, Path], 
                         file_extensions: Optional[List[str]] = None) -> BatchAnalysisResult:
        """
        ë””ë ‰í„°ë¦¬ ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ë¶„ì„
        
        Args:
            directory_path: ë¶„ì„í•  ë””ë ‰í„°ë¦¬ ê²½ë¡œ
            file_extensions: ì§€ì›í•  íŒŒì¼ í™•ì¥ì ëª©ë¡ (ê¸°ë³¸ê°’: ['.png', '.jpg', '.jpeg'])
            
        Returns:
            BatchAnalysisResult: ë°°ì¹˜ ë¶„ì„ ê²°ê³¼
        """
        if file_extensions is None:
            file_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']
        
        directory = Path(directory_path)
        if not directory.exists() or not directory.is_dir():
            raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ ë””ë ‰í„°ë¦¬: {directory_path}")
        
        # ì§€ì›ë˜ëŠ” í™•ì¥ìë¥¼ ê°€ì§„ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì°¾ê¸°
        image_paths = []
        for ext in file_extensions:
            image_paths.extend(directory.glob(f"*{ext}"))
            image_paths.extend(directory.glob(f"*{ext.upper()}"))
        
        if not image_paths:
            print(f"âš ï¸ ë””ë ‰í„°ë¦¬ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {directory_path}")
            return BatchAnalysisResult(
                results=[],
                total_images=0,
                total_detections=0,
                total_processing_time=0.0,
                average_processing_time=0.0,
                success_count=0,
                error_count=0,
                errors=[]
            )
        
        print(f" {len(image_paths)}ê°œ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬: {directory_path}")
        return self.analyze_batch(image_paths)
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        ì˜¤í† ë¼ë²¨ëŸ¬ í†µê³„ ì •ë³´ ë°˜í™˜
        
        Returns:
            Dict[str, Any]: í†µê³„ ì •ë³´
        """
        return {
            "cloud_provider": self.cloud_provider.value,
            "method": self.get_method_name(),
            "taxonomy_loaded": self.taxonomy is not None,
            "config": self.config
        }
    
    def validate_config(self) -> Tuple[bool, List[str]]:
        """
        ì„¤ì • ìœ íš¨ì„± ê²€ì¦
        
        Returns:
            Tuple[bool, List[str]]: (ìœ íš¨ì„± ì—¬ë¶€, ì˜¤ë¥˜ ë©”ì‹œì§€ ëª©ë¡)
        """
        errors = []
        
        # ê¸°ë³¸ ê²€ì¦
        if not self.config:
            errors.append("ì„¤ì •ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # í´ë¼ìš°ë“œ ì œê³µìë³„ ê²€ì¦
        if self.cloud_provider == CloudProvider.AWS:
            if "taxonomy_csv" not in self.config.get("data", {}):
                errors.append("AWS íƒì†Œë…¸ë¯¸ CSV ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        return len(errors) == 0, errors

    def _normalize_detections(self, detections: List[DetectionResult]) -> List[DetectionResult]:
        """íƒì†Œë…¸ë¯¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì§€ ê²°ê³¼ë¥¼ ì •ê·œí™”"""
        if not self.taxonomy:
            return detections # íƒì†Œë…¸ë¯¸ê°€ ì—†ìœ¼ë©´ ì •ê·œí™”í•˜ì§€ ì•ŠìŒ

        normalized_results = []
        for det in detections:
            taxonomy_result = self.taxonomy.normalize(det.label)
            det.canonical_name = taxonomy_result.canonical_name
            # ì‹ ë¢°ë„ ìœµí•© (ì›ë˜ ê°ì§€ ì‹ ë¢°ë„ì™€ íƒì†Œë…¸ë¯¸ ì‹ ë¢°ë„)
            det.confidence = det.confidence * taxonomy_result.confidence
            
            # ì„œë¹„ìŠ¤ ì½”ë“œ ì¶”ë¡  (ì„ íƒì )
            if hasattr(self, 'service_code_mapping') and det.canonical_name:
                det.service_code = self.service_code_mapping.get(det.canonical_name, None)
            
            normalized_results.append(det)
        return normalized_results
