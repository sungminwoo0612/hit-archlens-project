"""
Hit ArchLens CLI

í†µí•© ëª…ë ¹í–‰ ì¸í„°í˜ì´ìŠ¤ ë„êµ¬
"""

import click
import yaml
import json
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
from collections import defaultdict
from datetime import datetime
from dotenv import load_dotenv # load_dotenv ì„í¬íŠ¸
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

from ..core.providers.aws import (
    AWSCVAutoLabeler,
    AWSLLMAutoLabeler,
    AWSHybridAutoLabeler
)
from ..core.data_collectors import AWSDataCollector
from ..core.models import AnalysisResult, BatchAnalysisResult # BatchAnalysisResultë„ ì„í¬íŠ¸
from ..core.utils import visualizer # visualizer ëª¨ë“ˆ ì„í¬íŠ¸
import os


@click.group()
@click.version_option(version="1.0.0")
def cli():
    """
    Hit ArchLens CLI
    
    ë©€í‹° í´ë¼ìš°ë“œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ìë™ ë¶„ì„ ë„êµ¬
    """
    pass


def visualize_analysis_results(batch_results: BatchAnalysisResult, output_dir: Path, verbose: bool):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤ (ê·¸ë˜í”„ ë° ë°”ìš´ë”© ë°•ìŠ¤ ì´ë¯¸ì§€)."""
    visualizations_output_dir = output_dir / "visualizations"
    visualizations_output_dir.mkdir(parents=True, exist_ok=True)

    # ì£¼ìš” í†µê³„ ê·¸ë˜í”„
    visualizer.plot_detection_confidence(batch_results.results, visualizations_output_dir / "confidence_distribution.png", f"Detection Confidence ({batch_results.results[0].analysis_method.value})")
    visualizer.plot_service_distribution(batch_results.results, visualizations_output_dir / "service_distribution.png", title=f"Top Detected Services ({batch_results.results[0].analysis_method.value})")
    visualizer.plot_processing_time(batch_results, visualizations_output_dir / "processing_time.png", f"Processing Time ({batch_results.results[0].analysis_method.value})")
    visualizer.plot_detection_counts(batch_results.results, visualizations_output_dir / "detection_counts.png", f"Detection Counts ({batch_results.results[0].analysis_method.value})")
    visualizer.plot_normalization_success_rate(batch_results.results, visualizations_output_dir / "normalization_success_rate.png", f"Normalization Success Rate ({batch_results.results[0].analysis_method.value})")
    visualizer.plot_detection_status_distribution(batch_results.results, visualizations_output_dir / "detection_status_distribution.png", f"Detection Status ({batch_results.results[0].analysis_method.value})")

    # ê° ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    for ar in batch_results.results:
        if ar.success:
            # ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ëª…ì— _detections ì ‘ë¯¸ì‚¬ ì¶”ê°€
            image_name = ar.image_path.stem
            image_extension = ar.image_path.suffix
            output_image_path = visualizations_output_dir / f"{image_name}_detections{image_extension}"
            
            visualizer.draw_detections_on_image(
                image_path=ar.image_path,
                detections=ar.detections,
                output_path=output_image_path
            )
        else:
            if verbose:
                click.echo(f"âš ï¸ ë¶„ì„ ì‹¤íŒ¨í•œ ì´ë¯¸ì§€ ({ar.image_path.name})ëŠ” ì‹œê°í™”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
    visualizer.create_summary_report(batch_results, visualizations_output_dir)


def create_threshold_summary_report(
    all_threshold_results: Dict[float, BatchAnalysisResult], 
    output_base_dir: Path,
    method: str
) -> None:
    """
    ëª¨ë“  ì‹ ë¢°ë„ ì„ê³„ê°’ì— ëŒ€í•œ ë¶„ì„ í†µê³„ë¥¼ ìš”ì•½í•˜ì—¬ ë³´ê³ ì„œë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    summary_data = []
    for threshold, result in all_threshold_results.items():
        summary_data.append({
            "threshold": threshold,
            "method": method,
            "total_images": result.total_images,
            "successful_images": result.success_count,
            "failed_images": result.error_count,
            "success_rate": result.success_rate,
            "total_detections": result.total_detections,
            "average_detections_per_image": result.average_detections_per_image,
            "average_processing_time": result.average_processing_time,
            "average_confidence": result.average_confidence,
            "average_normalization_success_rate": result.average_normalization_success_rate
        })
    
    if not summary_data:
        click.echo("âš ï¸ ì‹ ë¢°ë„ ì„ê³„ê°’ë³„ ìš”ì•½ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_summary = pd.DataFrame(summary_data)
    
    summary_report_dir = output_base_dir / "evaluation" / "threshold_analysis"
    summary_report_dir.mkdir(parents=True, exist_ok=True)
    
    csv_path = summary_report_dir / f"{method}_threshold_summary.csv"
    df_summary.to_csv(csv_path, index=False)
    click.echo(f"\nâœ… ì‹ ë¢°ë„ ì„ê³„ê°’ë³„ ìš”ì•½ ë³´ê³ ì„œ ì €ì¥: {csv_path}")

    # ì‹œê°í™” ì¶”ê°€ (ì˜ˆì‹œ: ì‹ ë¢°ë„ë³„ ì„±ê³µë¥  ë³€í™”)
    visualizer.setup_plot_style()
    plt.figure()
    sns.lineplot(data=df_summary, x="threshold", y="success_rate", marker='o')
    plt.title(f"{method.upper()} Success Rate by Confidence Threshold")
    plt.xlabel("Confidence Threshold")
    plt.ylabel("Success Rate")
    plt.ylim(0, 1)
    plt.savefig(summary_report_dir / f"{method}_success_rate_by_threshold.png")
    plt.close()
    click.echo(f"âœ… ì‹ ë¢°ë„ ì„ê³„ê°’ë³„ ì„±ê³µë¥  ê·¸ë˜í”„ ì €ì¥: {summary_report_dir / f'{method}_success_rate_by_threshold.png'}")


@cli.command()
@click.option('--config', '-c', default='backend/configs/default.yaml', 
              help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
@click.option('--method', '-m', 
              type=click.Choice(['cv', 'llm', 'hybrid']), 
              default='hybrid',
              help='ë¶„ì„ ë°©ë²•')
@click.option('--output', '-o', default='data/outputs/experiments', # ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬
              help='ì¶œë ¥ ë””ë ‰í„°ë¦¬')
@click.option('--format', '-f',
              type=click.Choice(['json', 'csv', 'yaml']),\
              default='json',
              help='ì¶œë ¥ í˜•ì‹')
@click.option('--verbose', '-v', is_flag=True,
              help='ìƒì„¸ ì¶œë ¥')
@click.option('--confidence-thresholds', '-t', default='0.0,0.2,0.4,0.6,0.8', # ì¶”ê°€ëœ ì˜µì…˜
              help='ë¶„ì„ì— ì‚¬ìš©í•  ì‹ ë¢°ë„ ì„ê³„ê°’ ëª©ë¡ (ì½¤ë§ˆë¡œ êµ¬ë¶„, ì˜ˆ: 0.1,0.5,0.9)')
@click.argument('input_path')
def analyze(config, method, output, format, verbose, input_path, confidence_thresholds): # ì¸ìì— confidence_thresholds ì¶”ê°€
    """
    ì´ë¯¸ì§€ ë¶„ì„
    
    AWS ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ë¶„ì„í•˜ì—¬ ì„œë¹„ìŠ¤ ì•„ì´ì½˜ì„ ì¸ì‹í•©ë‹ˆë‹¤.
    
    INPUT_PATH: ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ë˜ëŠ” ë””ë ‰í„°ë¦¬ ê²½ë¡œ
    """
    try:
        # ì„¤ì • ë¡œë“œ
        config_data = load_config(config)
        
        # LLM API í‚¤ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        if "llm" in config_data:
            if "api_key" in config_data["llm"] and config_data["llm"]["api_key"].startswith("${") and config_data["llm"]["api_key"].endswith("}"):
                env_var_name = config_data["llm"]["api_key"][2:-1]
                config_data["llm"]["api_key"] = os.getenv(env_var_name, config_data["llm"]["api_key"])
                if config_data["llm"]["api_key"] == env_var_name:
                    print(f"âš ï¸ í™˜ê²½ ë³€ìˆ˜ '{env_var_name}'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ì‹ ë¢°ë„ ì„ê³„ê°’ íŒŒì‹±
        threshold_list = [float(t.strip()) for t in confidence_thresholds.split(',')]
        threshold_list.sort() # ë‚®ì€ ê°’ë¶€í„° ë†’ì€ ê°’ ìˆœìœ¼ë¡œ ì •ë ¬
        
        all_threshold_results: Dict[float, BatchAnalysisResult] = {}

        for threshold in threshold_list:
            click.echo(f"\n--- ğŸ“ˆ ë¶„ì„ ì‹œì‘: ì‹ ë¢°ë„ ì„ê³„ê°’ = {threshold:.1f} ---")
            
            # config_data['runtime']ì´ ì—†ì„ ê²½ìš° ì´ˆê¸°í™”
            if 'runtime' not in config_data:
                config_data['runtime'] = {}
            config_data['runtime']['conf_threshold'] = threshold # ëŸ°íƒ€ì„ ì„¤ì • ì—…ë°ì´íŠ¸

            # ì˜¤í† ë¼ë²¨ëŸ¬ ìƒì„± (ìƒˆë¡œìš´ ì„ê³„ê°’ìœ¼ë¡œ)
            labeler = create_auto_labeler(method, config_data)
            
            # ì…ë ¥ ê²½ë¡œ ì²˜ë¦¬
            current_input_path = Path(input_path)
            
            batch_results: BatchAnalysisResult
            if current_input_path.is_file():
                # ë‹¨ì¼ íŒŒì¼ ë¶„ì„
                results = [labeler.analyze_image(current_input_path)] 
                batch_results = BatchAnalysisResult(
                    results=results,
                    total_images=1,
                    total_detections=len(results[0].detections) if results and results[0].success else 0,
                    average_processing_time=results[0].processing_time if results and results[0].success else 0.0,
                    success_count=1 if results and results[0].success else 0,
                    error_count=0 if results and results[0].success else 1,
                    errors=[results[0].errors[0]] if results and not results[0].success and results[0].errors else []
                )
            elif current_input_path.is_dir():
                # ë””ë ‰í„°ë¦¬ ë¶„ì„
                image_files = find_image_files(current_input_path)
                if not image_files:
                    click.echo(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {current_input_path}")
                    return
                
                click.echo(f" {len(image_files)}ê°œ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬")
                batch_results = labeler.analyze_batch(image_files)
            else:
                click.echo(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ë¡œ: {current_input_path}")
                return

            all_threshold_results[threshold] = batch_results

            # ê²°ê³¼ ì €ì¥ ê²½ë¡œ ì„¤ì • (ì„ê³„ê°’ í¬í•¨)
            threshold_output_dir = Path(output) / f"{method}_results_conf_{str(threshold).replace('.', '_')}"
            threshold_output_dir.mkdir(parents=True, exist_ok=True)

            save_results(batch_results.results, threshold_output_dir, format, verbose)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ì‹œê°í™”
            visualize_analysis_results(batch_results, threshold_output_dir, verbose)

            # í†µê³„ ì¶œë ¥
            print_analysis_statistics(batch_results, verbose)
        
        # ëª¨ë“  ì„ê³„ê°’ì— ëŒ€í•œ ìµœì¢… í†µê³„ ë³´ê³ ì„œ ìƒì„±
        create_threshold_summary_report(all_threshold_results, Path(output), method)

    except Exception as e:
        click.echo(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        if verbose:
            import traceback
            traceback.print_exc()


@cli.command()
@click.option('--data-type', default='all', help='ìˆ˜ì§‘í•  ë°ì´í„° íƒ€ì… (icons, services, products, all)')
@click.option('--config', default='backend/configs/default.yaml', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
@click.option('--verbose', is_flag=True, help='ìƒì„¸ ì¶œë ¥')
@click.option('--monitor', is_flag=True, help='ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§')
def collect_data(data_type, config, verbose, monitor):
    """ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰"""
    try:
        # ì¶œë ¥ ë””ë ‰í„°ë¦¬ êµ¬ì¡° ì„¤ì •
        from ..core.data_collectors.setup_output_structure import setup_output_structure
        setup_output_structure()
        
        # ì„¤ì • ë¡œë“œ
        with open(config, 'r', encoding='utf-8') as f:
            config_data = yaml.safe_load(f)
        
        # AWS ì„¤ì •ê³¼ collectors ì„¤ì •ì„ ëª¨ë‘ í¬í•¨
        aws_config = {
            "region": config_data.get("aws", {}).get("region", "us-east-1"),
            "collectors": config_data.get("collectors", {}),
            "data_types": [data_type] if data_type != "all" else ["icons", "services", "products"],
            "output_dir": "data/outputs"  # data/outputs/ ë””ë ‰í„°ë¦¬ë¡œ ì„¤ì •
        }
        
        if verbose:
            print(f"ğŸ“‹ ì„¤ì • ì •ë³´:")
            print(f"   - ë¦¬ì „: {aws_config['region']}")
            print(f"   - ìˆ˜ì§‘ íƒ€ì…: {aws_config['data_types']}")
            print(f"   - ì¶œë ¥ ë””ë ‰í„°ë¦¬: {aws_config['output_dir']}")
            print(f"   - ì•„ì´ì½˜ ZIP: {aws_config['collectors'].get('icons', {}).get('zip_path', 'Not set')}")
            print(f"   - ì œí’ˆ API: {aws_config['collectors'].get('products', {}).get('api_url', 'Not set')}")
        
        # AWS ë°ì´í„° ìˆ˜ì§‘ê¸° ìƒì„±
        collector = AWSDataCollector(aws_config)
        
        if monitor:
            # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëª¨ë“œ
            print("ğŸ” ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëª¨ë“œ ì‹œì‘")
            print("Ctrl+Cë¡œ ì¤‘ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            
            import threading
            import time
            
            def monitor_progress():
                while True:
                    progress = collector.get_progress()
                    if progress["current_task"]:
                        print(f"\r {progress['current_task']}: {progress['progress_percentage']:.1f}% "
                              f"({progress['detailed_status'].get('processed', 0)}/"
                              f"{progress['detailed_status'].get('total', 0)})", end="")
                    time.sleep(1)
            
            # ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘
            monitor_thread = threading.Thread(target=monitor_progress, daemon=True)
            monitor_thread.start()
        
        # ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
        result = collector.collect()
        
        if result.success:
            print(f"\nâœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
            print(f"   - ìˆ˜ì§‘ëœ í•­ëª©: {result.data_count}ê°œ")
            print(f"   - ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
            print(f"   - ì¶œë ¥ íŒŒì¼: {len(result.output_paths)}ê°œ")
            print(f"   - ì €ì¥ ìœ„ì¹˜: data/outputs/ ë””ë ‰í„°ë¦¬")
        else:
            print(f"\nâŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨!")
            print(f"   - ì˜¤ë¥˜: {', '.join(result.errors)}")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if verbose:
            import traceback
            traceback.print_exc()


@cli.command()
@click.option('--config', '-c', default='backend/configs/default.yaml',
              help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
@click.option('--method', '-m',
              type=click.Choice(['cv', 'llm', 'hybrid']),
              default='hybrid',
              help='ë¶„ì„ ë°©ë²•')
def status(config, method):
    """
    ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    
    ì˜¤í† ë¼ë²¨ëŸ¬ì™€ ë°ì´í„° ìˆ˜ì§‘ê¸°ì˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    try:
        # ì„¤ì • ë¡œë“œ
        config_data = load_config(config)
        
        click.echo("ğŸ” ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
        click.echo("=" * 50)
        
        # ì˜¤í† ë¼ë²¨ëŸ¬ ìƒíƒœ
        click.echo("ğŸ“Š ì˜¤í† ë¼ë²¨ëŸ¬ ìƒíƒœ:")
        labeler = create_auto_labeler(method, config_data)
        labeler_stats = labeler.get_statistics()
        
        for key, value in labeler_stats.items():
            click.echo(f"   {key}: {value}")
        
        click.echo()
        
        # ë°ì´í„° ìˆ˜ì§‘ê¸° ìƒíƒœ
        click.echo("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ê¸° ìƒíƒœ:")
        collector = AWSDataCollector(config_data)
        collector_stats = collector.get_collection_status()
        
        for key, value in collector_stats.items():
            click.echo(f"   {key}: {value}")
        
        click.echo()
        click.echo("âœ… ìƒíƒœ í™•ì¸ ì™„ë£Œ")
        
    except Exception as e:
        click.echo(f"âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")


@cli.command()
@click.option('--config', '-c', default='backend/configs/default.yaml',
              help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
@click.option('--method', '-m',
              type=click.Choice(['cv', 'llm', 'hybrid']),
              default='hybrid',
              help='ë¶„ì„ ë°©ë²•')
@click.option('--output', '-o', default='output',
              help='ì¶œë ¥ ë””ë ‰í„°ë¦¬')
@click.argument('input_path')
def compare_methods(config, method, output, input_path):
    """
    ë¶„ì„ ë°©ë²• ë¹„êµ
    
    CV, LLM, í•˜ì´ë¸Œë¦¬ë“œ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
    """
    try:
        # ì„¤ì • ë¡œë“œ
        config_data = load_config(config)
        
        # ì…ë ¥ ê²½ë¡œ ì²˜ë¦¬
        input_path = Path(input_path)
        if not input_path.is_file():
            click.echo(f"âŒ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {input_path}")
            return
        
        click.echo("ğŸ” ë¶„ì„ ë°©ë²• ë¹„êµ ì‹œì‘")
        
        # ê° ë°©ë²•ë³„ ë¶„ì„
        methods = ['cv', 'llm', 'hybrid']
        results = {}
        
        for method_name in methods:
            click.echo(f"   ï¿½ï¿½ {method_name.upper()} ë¶„ì„ ì¤‘...")
            labeler = create_auto_labeler(method_name, config_data)
            result = labeler.analyze_image(input_path)
            results[method_name] = result
        
        # ê²°ê³¼ ë¹„êµ
        output_dir = Path(output)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        comparison_data = {
            "input_image": str(input_path),
            "image_size": (results['cv'].width, results['cv'].height),
            "methods": {}
        }
        
        for method_name, result in results.items():
            comparison_data["methods"][method_name] = {
                "detection_count": len(result.detections),
                "processing_time": result.processing_time,
                "average_confidence": result.average_confidence,
                "detections": [det.to_dict() for det in result.detections]
            }
        
        # ê²°ê³¼ ì €ì¥
        comparison_path = output_dir / "method_comparison.json"
        with open(comparison_path, 'w', encoding='utf-8') as f:
            json.dump(comparison_data, f, indent=2, ensure_ascii=False)
        
        # ë¹„êµ ê²°ê³¼ ì¶œë ¥
        click.echo("\nğŸ“Š ë¶„ì„ ë°©ë²• ë¹„êµ ê²°ê³¼:")
        click.echo("-" * 50)
        for method_name, data in comparison_data["methods"].items():
            click.echo(f"{method_name.upper():>8}: "
                      f"{data['detection_count']:>3}ê°œ ê°ì§€, "
                      f"{data['processing_time']:>6.2f}ì´ˆ, "
                      f"í‰ê·  ì‹ ë¢°ë„: {data['average_confidence']:.3f}")
        
        click.echo(f"\nğŸ“„ ìƒì„¸ ê²°ê³¼ ì €ì¥: {comparison_path}")
        
    except Exception as e:
        click.echo(f"âŒ ë°©ë²• ë¹„êµ ì‹¤íŒ¨: {e}")


@cli.command()
@click.argument('results_dir')
def visualize(output, results_dir):
    """
    ë¶„ì„ ê²°ê³¼ ì‹œê°í™”
    
    ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ í†µê³„ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    RESULTS_DIR: analyze ëª…ë ¹ì–´ë¡œ ìƒì„±ëœ JSON ê²°ê³¼ íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í„°ë¦¬
    """
    try:
        results_path = Path(results_dir)
        if not results_path.is_dir():
            click.echo(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ë””ë ‰í„°ë¦¬: {results_dir}")
            return
        
        # JSON ê²°ê³¼ íŒŒì¼ ë¡œë“œ
        analysis_results: List[AnalysisResult] = []
        for file_path in results_path.glob("*.json"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    analysis_results.append(AnalysisResult.from_dict(data))
            except Exception as e:
                click.echo(f"âš ï¸ ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file_path} - {e}")
                continue
        
        if not analysis_results:
            click.echo("âŒ ì‹œê°í™”í•  ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°°ì¹˜ ë¶„ì„ ê²°ê³¼ ê°ì²´ ìƒì„± (í†µê³„ ê³„ì‚°ìš©)
        total_detections = sum(r.detection_count for r in analysis_results)
        total_processing_time = sum(r.processing_time for r in analysis_results)
        
        batch_results = BatchAnalysisResult(
            results=analysis_results,
            total_images=len(analysis_results),
            total_detections=total_detections,
            average_processing_time=total_processing_time / len(analysis_results) if analysis_results else 0.0,
            success_count=len(analysis_results), # ì—¬ê¸°ì„œëŠ” ëª¨ë“  ë¡œë“œëœ íŒŒì¼ì´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
            error_count=0
        )
        
        output_dir = Path(output)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        click.echo(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ ì‹œê°í™” ì‹œì‘: {results_dir}")
        
        # 1. ì‹ ë¢°ë„ ë¶„í¬
        visualizer.plot_confidence_distribution(
            analysis_results, output_dir / "confidence_distribution.png",
            title=f"Confidence Distribution ({batch_results.results[0].analysis_method.value.upper()})"
        )
        
        # 2. ì²˜ë¦¬ ì‹œê°„
        visualizer.plot_processing_time(
            analysis_results, output_dir / "processing_time.png"
        )
        
        # 3. ê°ì§€ ìˆ˜
        visualizer.plot_detection_counts(
            analysis_results, output_dir / "detection_counts.png"
        )

        # 4. ì„œë¹„ìŠ¤ ë¶„í¬
        visualizer.plot_service_distribution(
            analysis_results, output_dir / "service_distribution.png"
        )

        # 5. ì •ê·œí™” ì„±ê³µë¥ 
        visualizer.plot_normalization_success_rate(
            analysis_results, output_dir / "normalization_success_rate.png"
        )
        
        # 6. ìš”ì•½ ë³´ê³ ì„œ
        visualizer.create_summary_report(batch_results, output_dir)
        
        click.echo(f"âœ… ì‹œê°í™” ì™„ë£Œ. ê²°ê³¼ëŠ” '{output_dir}' ë””ë ‰í„°ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        click.echo(f"âŒ ì‹œê°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


@cli.command()
@click.option('--data-dir', default='out', help='ë°ì´í„° ë””ë ‰í„°ë¦¬ ê²½ë¡œ')
@click.option('--verbose', is_flag=True, help='ìƒì„¸ ì¶œë ¥')
def generate_unified_taxonomy(data_dir, verbose):
    """í†µí•© íƒì†Œë…¸ë¯¸ ìƒì„±"""
    try:
        from ..core.data_collectors.unified_taxonomy_generator import generate_unified_taxonomy
        
        print("ğŸ” í†µí•© íƒì†Œë…¸ë¯¸ ìƒì„± ì‹œì‘")
        
        success = generate_unified_taxonomy(data_dir)
        
        if success:
            print("âœ… í†µí•© íƒì†Œë…¸ë¯¸ ìƒì„± ì™„ë£Œ")
            print(f"   - ì¶œë ¥ ìœ„ì¹˜: {data_dir}/unified/")
            print(f"   - íŒŒì¼: aws_unified_taxonomy.csv, aws_unified_taxonomy.json")
        else:
            print("âŒ í†µí•© íƒì†Œë…¸ë¯¸ ìƒì„± ì‹¤íŒ¨")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if verbose:
            import traceback
            traceback.print_exc()


@cli.command()
@click.option('--config', '-c', default='backend/configs/default.yaml',
              help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
@click.option('--input', '-i', required=True, help='ì‹œê°í™”í•  ë¶„ì„ ê²°ê³¼ ë””ë ‰í„°ë¦¬ ë˜ëŠ” íŒŒì¼ ê²½ë¡œ')
@click.option('--output', '-o', default='data/outputs/visualizations', help='ì‹œê°í™” ê²°ê³¼ ì €ì¥ ë””ë ‰í„°ë¦¬')
@click.option('--verbose', '-v', is_flag=True, help='ìƒì„¸ ì¶œë ¥')
def visualize(config, input, output, verbose):
    """
    ë¶„ì„ ê²°ê³¼ ì‹œê°í™”
    
    ë¶„ì„ ê²°ê³¼ë¥¼ ê·¸ë˜í”„ ë° ì°¨íŠ¸ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    try:
        config_data = load_config(config)
        
        input_path = Path(input)
        output_path = Path(output)
        output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ ì‹œê°í™” ì‹œì‘: {input_path}")
        
        # BatchAnalysisResult ë¡œë“œ (analyze ëª…ë ¹ì–´ì—ì„œ ì €ì¥í•œ í˜•ì‹)
        if input_path.is_dir():
            # ë””ë ‰í„°ë¦¬ì¸ ê²½ìš° ëª¨ë“  analysis_result_*.json íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ BatchAnalysisResultë¡œ í†µí•©
            analysis_results = []
            for json_file in input_path.glob("analysis_result_*.json"):
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    analysis_results.append(AnalysisResult(**data))
            
            if not analysis_results:
                click.echo(f"âŒ ì‹œê°í™”í•  ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
                return
            
            batch_results = BatchAnalysisResult(
                results=analysis_results,
                total_images=len(analysis_results),
                total_detections=sum(len(ar.detections) for ar in analysis_results),
                average_processing_time=sum(ar.processing_time for ar in analysis_results) / len(analysis_results) if analysis_results else 0,
                success_count=sum(1 for ar in analysis_results if ar.success),
                error_count=sum(1 for ar in analysis_results if not ar.success)
            )
            
        elif input_path.is_file() and input_path.name.startswith("analysis_result_") and input_path.name.endswith(".json"):
            with open(input_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                analysis_result = AnalysisResult(**data)
                batch_results = BatchAnalysisResult(
                    results=[analysis_result],
                    total_images=1,
                    total_detections=len(analysis_result.detections),
                    average_processing_time=analysis_result.processing_time,
                    success_count=1 if analysis_result.success else 0,
                    error_count=0 if analysis_result.success else 1
                )
        else:
            click.echo(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì…ë ¥ ê²½ë¡œ ë˜ëŠ” íŒŒì¼ í˜•ì‹: {input_path}")
            return
        
        # ì‹œê°í™” í•¨ìˆ˜ í˜¸ì¶œ
        visualizer.plot_detection_confidence(batch_results.results, output_path / "confidence_distribution.png")
        visualizer.plot_service_distribution(batch_results.results, output_path / "service_distribution.png")
        visualizer.plot_processing_time(batch_results, output_path / "processing_time.png")
        
        print(f"âœ… ì‹œê°í™” ì™„ë£Œ. ê²°ê³¼ëŠ” '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        click.echo(f"âŒ ì‹œê°í™” ì‹¤íŒ¨: {e}")
        if verbose:
            import traceback
            traceback.print_exc()


@cli.command()
@click.option('--config', '-c', default='backend/configs/default.yaml',
              help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
@click.option('--method', '-m',
              type=click.Choice(['cv', 'llm', 'hybrid']),
              default='hybrid',
              help='ë¶„ì„ ë°©ë²•')
@click.option('--verbose', '-v', is_flag=True,
              help='ìƒì„¸ ì¶œë ¥')
def status(config, method, verbose):
    """
    ì‹œìŠ¤í…œ ìƒíƒœ ë° í†µê³„ í™•ì¸
    
    í˜„ì¬ ì‹œìŠ¤í…œì˜ ì„¤ì •, ìˆ˜ì§‘ëœ ë°ì´í„° ë° ë¶„ì„ í†µê³„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    try:
        config_data = load_config(config)
        
        # ë°ì´í„° ìˆ˜ì§‘ê¸° ìƒíƒœ
        collector = AWSDataCollector(config_data.get("aws", {}))
        collection_status = collector.get_collection_status()
        
        click.echo("\n--- ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ìƒíƒœ ---")
        for key, value in collection_status.items():
            if isinstance(value, float):
                click.echo(f"   {key}: {value:.2f}")
            else:
                click.echo(f"   {key}: {value}")
        
        # ì˜¤í† ë¼ë²¨ëŸ¬ í†µê³„ (ì„ì‹œ êµ¬í˜„)
        # ì‹¤ì œë¡œëŠ” ê° ë¼ë²¨ëŸ¬ì—ì„œ í†µê³„ë¥¼ ê°€ì ¸ì™€ì•¼ í•¨
        click.echo("\n--- ğŸ“ˆ ì˜¤í† ë¼ë²¨ëŸ¬ í†µê³„ (ì˜ˆì •) ---")
        click.echo(f"   ì„ íƒëœ ë°©ë²•: {method}")
        click.echo("   * ì´ ë¶€ë¶„ì€ í–¥í›„ ê° ì˜¤í† ë¼ë²¨ëŸ¬ ëª¨ë“ˆì˜ ìƒì„¸ í†µê³„ë¡œ ì±„ì›Œì§ˆ ì˜ˆì •ì…ë‹ˆë‹¤.")
        
    except Exception as e:
        click.echo(f"âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        if verbose:
            import traceback
            traceback.print_exc()


def load_config(config_path: str) -> Dict[str, Any]:
    """ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    with open(config_path, 'r', encoding='utf-8') as f:
        config_data = yaml.safe_load(f)
    return config_data


def create_auto_labeler(method: str, config: Dict[str, Any]):
    """ì„ íƒëœ ë°©ë²•ì— ë”°ë¼ ì˜¤í† ë¼ë²¨ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if method == "cv":
        return AWSCVAutoLabeler(config)
    elif method == "llm":
        return AWSLLMAutoLabeler(config)
    elif method == "hybrid":
        return AWSHybridAutoLabeler(config)
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ì„ ë°©ë²•: {method}")


def find_image_files(directory: Path) -> List[Path]:
    """ë””ë ‰í„°ë¦¬ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ì„ ì°¾ìŠµë‹ˆë‹¤."""
    image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.gif', '*.bmp', '*.tiff']
    files = []
    for ext in image_extensions:
        files.extend(directory.rglob(ext))
    return files


def save_results(results: List[AnalysisResult], output_dir: Path, format: str, verbose: bool):
    """ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    for i, result in enumerate(results):
        file_name = f"analysis_result_{i:03d}.json"
        output_path = output_dir / file_name
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result.to_dict(), f, indent=2, ensure_ascii=False)
        if verbose:
            click.echo(f"ğŸ“„ ê²°ê³¼ ì €ì¥: {output_path}")


def print_analysis_statistics(batch_results: BatchAnalysisResult, verbose: bool):
    """ë¶„ì„ í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    click.echo("\n ë¶„ì„ í†µê³„:")
    click.echo(f"   ì´ë¯¸ì§€ ìˆ˜: {batch_results.total_images}")
    click.echo(f"   ì´ ê°ì§€ ìˆ˜: {batch_results.total_detections}")
    click.echo(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {batch_results.average_processing_time:.2f}ì´ˆ")
    
    # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚° (ëª¨ë“  AnalysisResultì˜ í‰ê· )
    if batch_results.results:
        all_confidences = [d.confidence for ar in batch_results.results for d in ar.detections]
        if all_confidences:
            avg_confidence = sum(all_confidences) / len(all_confidences)
            click.echo(f"   í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
        else:
            click.echo(f"   í‰ê·  ì‹ ë¢°ë„: N/A (ê°ì§€ëœ ê°ì²´ ì—†ìŒ)")
    else:
        click.echo(f"   í‰ê·  ì‹ ë¢°ë„: N/A (ë¶„ì„ ê²°ê³¼ ì—†ìŒ)")
        
    if verbose:
        click.echo(f"   ì„±ê³µí•œ ì´ë¯¸ì§€: {batch_results.success_count}")
        click.echo(f"   ì‹¤íŒ¨í•œ ì´ë¯¸ì§€: {batch_results.error_count}")


def print_collection_statistics(stats):
    """ìˆ˜ì§‘ í†µê³„ ì¶œë ¥"""
    click.echo(f"\nï¿½ï¿½ ìˆ˜ì§‘ í†µê³„:")
    click.echo(f"   ì´ ìˆ˜ì§‘: {stats.total_collections}")
    click.echo(f"   ì„±ê³µ: {stats.successful_collections}")
    click.echo(f"   ì‹¤íŒ¨: {stats.failed_collections}")
    click.echo(f"   ì„±ê³µë¥ : {stats.success_rate:.1%}")
    click.echo(f"   ì´ ë°ì´í„° ìˆ˜: {stats.total_data_count}")
    click.echo(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {stats.average_processing_time:.2f}ì´ˆ")


if __name__ == '__main__':
    cli()
