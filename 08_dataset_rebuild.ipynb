{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset 재구성\n",
        "\nTaxonomy 및 train/val/test split 재생성\n",
        "\n**원본 스크립트**: `aws_icon_dataset_rebuild.sh`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 개요\n",
        "AWS 아이콘 taxonomy + train/val/test split 재생성\n\n",
        "### 사용법\n",
        "```bash\n",
        "./aws_icon_dataset_rebuild.sh ./dataset/icons\n",
        "```\n\n",
        "### 인자\n",
        "- `$1`: CSV 파일이 들어있는 디렉터리 (기본값: ./dataset/icons)\n\n",
        "### 동작\n",
        "기존 labels_coarse.csv / labels_fine.csv / train/val/test_fine.csv 기준으로 재계산을 수행합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "set -euo pipefail\n",
        "DATA_DIR=\"${1:-./dataset/icons}\"\n",
        "export DATA_DIR\n",
        "if [ ! -d \"$DATA_DIR\" ]; then\n",
        "  echo \"ERROR: DATA_DIR '$DATA_DIR' 디렉터리가 없습니다.\" >&2\n",
        "  exit 1\n",
        "fi\n",
        "echo \"[INFO] DATA_DIR = $DATA_DIR\"\n",
        "echo \"[INFO] 기존 labels_coarse.csv / labels_fine.csv / train/val/test_fine.csv 기준으로 재계산을 수행합니다.\"\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import os\n",
        "import json\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ----- 설정 -----\n",
        "DATA_DIR = os.environ[\"DATA_DIR\"]\n",
        "data_path = Path(DATA_DIR)\n",
        "\n",
        "# ----- labels csv 자동 탐색 (안전장치) -----\n",
        "def find_csv(root: Path, name: str):\n",
        "    for p in root.rglob(name):\n",
        "        return p\n",
        "    return None\n",
        "\n",
        "labels_fine_path = find_csv(data_path, \"labels_fine.csv\")\n",
        "labels_coarse_path = find_csv(data_path, \"labels_coarse.csv\")\n",
        "\n",
        "if labels_fine_path is None:\n",
        "    raise FileNotFoundError(\"labels_fine.csv not found anywhere under DATA_DIR\")\n",
        "if labels_coarse_path is None:\n",
        "    raise FileNotFoundError(\"labels_coarse.csv not found anywhere under DATA_DIR\")\n",
        "\n",
        "print(f\"[INFO] Using labels_fine.csv: {labels_fine_path}\")\n",
        "print(f\"[INFO] Using labels_coarse.csv: {labels_coarse_path}\")\n",
        "\n",
        "print(f\"[INFO] Load: {labels_fine_path}\")\n",
        "df_fine = pd.read_csv(labels_fine_path)\n",
        "\n",
        "print(f\"[INFO] Load: {labels_coarse_path}\")\n",
        "df_coarse = pd.read_csv(labels_coarse_path)\n",
        "\n",
        "# ============================================\n",
        "# 1. Taxonomy 재구성 (coarse / fine)\n",
        "# ============================================\n",
        "\n",
        "# coarse taxonomy\n",
        "coarse_counts = df_fine[\"coarse_class\"].value_counts().sort_index()\n",
        "df_tax_coarse = pd.DataFrame({\n",
        "    \"coarse_class\": coarse_counts.index,\n",
        "    \"num_icons_fine\": coarse_counts.values,\n",
        "})\n",
        "\n",
        "coarse_out = data_path / \"taxonomy_coarse.csv\"\n",
        "df_tax_coarse.to_csv(coarse_out, index=False)\n",
        "print(f\"[OK] taxonomy_coarse.csv 저장: {coarse_out} (rows={len(df_tax_coarse)})\")\n",
        "\n",
        "# fine taxonomy (canonical_service_name + coarse + count)\n",
        "fine_group = df_fine.groupby(\n",
        "    [\"coarse_class\", \"canonical_service_name\"], as_index=False\n",
        ").agg(num_icons=(\"file_path\", \"count\"))\n",
        "\n",
        "fine_group = fine_group.sort_values(\n",
        "    [\"coarse_class\", \"canonical_service_name\"]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "fine_out = data_path / \"taxonomy_fine.csv\"\n",
        "fine_group.to_csv(fine_out, index=False)\n",
        "print(f\"[OK] taxonomy_fine.csv 저장: {fine_out} (rows={len(fine_group)})\")\n",
        "\n",
        "# stage1/2 class 리스트 텍스트 (라벨링/YOLO names용)\n",
        "stage1_path = data_path / \"stage1_classes.txt\"\n",
        "stage2_path = data_path / \"stage2_classes.txt\"\n",
        "\n",
        "coarse_list = list(coarse_counts.index)\n",
        "fine_list = list(fine_group[\"canonical_service_name\"].unique())\n",
        "\n",
        "stage1_path.write_text(\"\\n\".join(coarse_list), encoding=\"utf-8\")\n",
        "stage2_path.write_text(\"\\n\".join(fine_list), encoding=\"utf-8\")\n",
        "\n",
        "print(f\"[OK] stage1_classes.txt 저장: {stage1_path} (coarse {len(coarse_list)}개)\")\n",
        "print(f\"[OK] stage2_classes.txt 저장: {stage2_path} (fine {len(fine_list)}개)\")\n",
        "\n",
        "# ============================================\n",
        "# 2. train/val/test split 재생성 (stratified by coarse_class)\n",
        "#    - 기본 비율: 0.7 / 0.15 / 0.15\n",
        "# ============================================\n",
        "\n",
        "N = len(df_fine)\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# 1st: train vs (val+test)\n",
        "df_train, df_tmp = train_test_split(\n",
        "    df_fine,\n",
        "    test_size=(1.0 - train_ratio),\n",
        "    stratify=df_fine[\"coarse_class\"],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "# 2nd: (val+test) → val / test\n",
        "tmp_ratio = 1.0 - train_ratio\n",
        "val_fraction = val_ratio / tmp_ratio  # (val+test) 내부에서 다시 분할\n",
        "\n",
        "df_val, df_test = train_test_split(\n",
        "    df_tmp,\n",
        "    test_size=(1.0 - val_fraction),\n",
        "    stratify=df_tmp[\"coarse_class\"],\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "# 정렬(옵션) - file_path 기준\n",
        "df_train = df_train.sort_values(\"file_path\").reset_index(drop=True)\n",
        "df_val = df_val.sort_values(\"file_path\").reset_index(drop=True)\n",
        "df_test = df_test.sort_values(\"file_path\").reset_index(drop=True)\n",
        "\n",
        "train_out = data_path / \"train_fine.csv\"\n",
        "val_out = data_path / \"val_fine.csv\"\n",
        "test_out = data_path / \"test_fine.csv\"\n",
        "\n",
        "df_train.to_csv(train_out, index=False)\n",
        "df_val.to_csv(val_out, index=False)\n",
        "df_test.to_csv(test_out, index=False)\n",
        "\n",
        "print(f\"[OK] train_fine.csv 저장: {train_out} (rows={len(df_train)})\")\n",
        "print(f\"[OK] val_fine.csv 저장:   {val_out} (rows={len(df_val)})\")\n",
        "print(f\"[OK] test_fine.csv 저장:  {test_out} (rows={len(df_test)})\")\n",
        "\n",
        "# ============================================\n",
        "# 3. split 통계 JSON 생성 (train_val_test_split.json)\n",
        "# ============================================\n",
        "\n",
        "def stats_for(df):\n",
        "    coarse = df[\"coarse_class\"].value_counts().to_dict()\n",
        "    fine = df[\"canonical_service_name\"].value_counts().to_dict()\n",
        "    return {\n",
        "        \"count\": int(len(df)),\n",
        "        \"coarse_distribution\": {k: int(v) for k, v in coarse.items()},\n",
        "        \"fine_distribution\": {k: int(v) for k, v in fine.items()},\n",
        "    }\n",
        "\n",
        "split_stats = {\n",
        "    \"train\": stats_for(df_train),\n",
        "    \"val\": stats_for(df_val),\n",
        "    \"test\": stats_for(df_test),\n",
        "}\n",
        "\n",
        "json_out = data_path / \"train_val_test_split.json\"\n",
        "json_out.write_text(json.dumps(split_stats, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
        "print(f\"[OK] train_val_test_split.json 저장: {json_out}\")\n",
        "\n",
        "print(\"[DONE] taxonomy + split + stats 재생성 완료.\")\n",
        "PY\n",
        "\n"
      ],
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}