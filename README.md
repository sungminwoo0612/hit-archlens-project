# Hit ArchLens

ë©€í‹° í´ë¼ìš°ë“œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ìë™ ë¶„ì„ì„ ìœ„í•œ í†µí•© í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. Computer Visionê³¼ Large Language Modelì„ ê²°í•©í•˜ì—¬ í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì•„ì´ì½˜ì„ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ê³  ë¶„ë¥˜í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

- **Computer Vision ê¸°ë°˜ ë¶„ì„**: CLIP ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê²€ìƒ‰
- **LLM ê¸°ë°˜ ë¶„ì„**: GPT-4 Visionì„ í™œìš©í•œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„
- **í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„**: CVì™€ LLM ê²°ê³¼ë¥¼ ìœµí•©í•œ ê³ ì •í™•ë„ ë¶„ì„
- **AWS ë°ì´í„° ìˆ˜ì§‘**: ì•„ì´ì½˜, ì„œë¹„ìŠ¤ ì •ë³´, ì œí’ˆ ì •ë³´ ìë™ ìˆ˜ì§‘
- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ê³¼ì • ì‹¤ì‹œê°„ ì¶”ì 
- **ì„±ëŠ¥ ì‹œê°í™”**: ë¶„ì„ ê²°ê³¼ ë° í†µê³„ ë°ì´í„° ì‹œê°í™”

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```bash
Hit ArchLens/
â”œâ”€â”€ backend/                 # ë°±ì—”ë“œ íŒ¨í‚¤ì§€
â”‚   â”œâ”€â”€ core/               # í•µì‹¬ í”„ë ˆì„ì›Œí¬
â”‚   â”‚   â”œâ”€â”€ auto_labeler/   # ì˜¤í† ë¼ë²¨ë§ ì¶”ìƒ í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ data_collectors/# ë°ì´í„° ìˆ˜ì§‘ í”„ë ˆì„ì›Œí¬
â”‚   â”‚   â”œâ”€â”€ models.py       # í†µí•© ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ taxonomy/       # ì„œë¹„ìŠ¤ ë¶„ë¥˜ ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ providers/      # í´ë¼ìš°ë“œë³„ êµ¬í˜„ì²´
â”‚   â”‚   â”‚   â””â”€â”€ aws/        # AWS ì „ìš© êµ¬í˜„ì²´
â”‚   â”‚   â”‚       â”œâ”€â”€ cv/     # CV ê¸°ë°˜ ì˜¤í† ë¼ë²¨ëŸ¬
â”‚   â”‚   â”‚       â”œâ”€â”€ llm/    # LLM ê¸°ë°˜ ì˜¤í† ë¼ë²¨ëŸ¬
â”‚   â”‚   â”‚       â””â”€â”€ hybrid/ # í•˜ì´ë¸Œë¦¬ë“œ ì˜¤í† ë¼ë²¨ëŸ¬
â”‚   â”‚   â””â”€â”€ utils/          # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â”œâ”€â”€ tools/              # CLI ë„êµ¬
â”‚   â””â”€â”€ configs/            # ì„¤ì • íŒŒì¼
â”œâ”€â”€ data/                   # ëª¨ë“  ë°ì´í„° í†µí•©
â”‚   â”œâ”€â”€ aws/                # AWS ë°ì´í„°
â”‚   â”œâ”€â”€ images/             # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
â”‚   â””â”€â”€ outputs/            # ì¶œë ¥ ê²°ê³¼ë¬¼
â”œâ”€â”€ archive/                # ë ˆê±°ì‹œ ë°±ì—…
â”œâ”€â”€ cache/                  # ìºì‹œ íŒŒì¼
â”œâ”€â”€ docs/                   # ë¬¸ì„œ
â”œâ”€â”€ examples/               # ì˜ˆì œ íŒŒì¼
â””â”€â”€ scripts/                # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼
```

## âš™ï¸ ì„¤ì •

### ê¸°ë³¸ ì„¤ì • íŒŒì¼: `backend/configs/default.yaml`

```yaml
# ë°ì´í„° ì„¤ì •
data:
  icons_dir: "data/outputs/aws/icons"
  taxonomy_csv: "data/aws/aws_resources_models.csv"
  images_dir: "data/images"
  output_dir: "data/outputs"

# CV ì„¤ì •
cv:
  clip_name: "ViT-B-32"
  clip_pretrained: "laion2b_s34b_b79k"
  device: "auto"

# LLM ì„¤ì •
llm:
  provider: "openai"
  api_key: "${OPENAI_API_KEY}"
  vision_model: "gpt-4-vision-preview"

# ë¶„ì„ ì„¤ì •
detection:
  max_size: 1600
  min_area: 900
  max_area: 90000

# ì„±ëŠ¥ ì„¤ì •
performance:
  parallel_processing: true
  max_workers: 4
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd hit_archlens

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ë˜ëŠ” venv\Scripts\activate  # Windows

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. AWS ì•„ì´ì½˜ ë‹¤ìš´ë¡œë“œ

```bash
# AWS ê³µì‹ ì•„í‚¤í…ì²˜ ì•„ì´ì½˜ ë‹¤ìš´ë¡œë“œ
wget https://d1.awsstatic.com/webteam/architecture-icons/q1-2024/Asset-Package_01242024.7c4f8b8b.zip -O Asset-Package.zip

# ë˜ëŠ” AWS ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ:
# https://aws.amazon.com/ko/architecture/icons/
```

### 3. ë°ì´í„° ìˆ˜ì§‘

```bash
# ëª¨ë“  AWS ë°ì´í„° ìˆ˜ì§‘ (ì•„ì´ì½˜, ì„œë¹„ìŠ¤, ì œí’ˆ ì •ë³´)
python cli.py collect-data --data-type all --monitor --verbose

# ë˜ëŠ” pyproject.toml ì„¤ì¹˜ í›„
archlens collect-data --data-type all --monitor --verbose

# íŠ¹ì • ë°ì´í„°ë§Œ ìˆ˜ì§‘
python cli.py collect-data --data-type icons --verbose
python cli.py collect-data --data-type services --verbose
python cli.py collect-data --data-type products --verbose
```

### 4. ì˜¤í† ë¼ë²¨ë§ ë¶„ì„

```bash
# CV ê¸°ë°˜ ë¶„ì„ (API í‚¤ ë¶ˆí•„ìš”)
python cli.py analyze --input data/images/test_diagram.png --method cv --output data/outputs/experiments/cv_results --verbose

# LLM ê¸°ë°˜ ë¶„ì„ (OpenAI API í‚¤ í•„ìš”)
export OPENAI_API_KEY="your-api-key-here"
python cli.py analyze --input data/images/test_diagram.png --method llm --output data/outputs/experiments/llm_results --verbose

# í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ (CV + LLM ê²°í•©)
python cli.py analyze --input data/images/test_diagram.png --method hybrid --output data/outputs/experiments/hybrid_results --verbose
```

### 5. ë°°ì¹˜ ë¶„ì„

```bash
# ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ë¶„ì„
python cli.py analyze --input data/images/ --method hybrid --output data/outputs/experiments/batch_results --verbose
```

### 6. ê²°ê³¼ ì‹œê°í™”

```bash
# ë¶„ì„ ê²°ê³¼ ì‹œê°í™”
python cli.py visualize --input data/outputs/experiments/hybrid_results --output data/outputs/visualizations --verbose
```

## ğŸ“Š ìˆœì°¨ì  ì‚¬ìš© ê°€ì´ë“œ

### Phase 1: ì´ˆê¸° ì„¤ì • ë° ë°ì´í„° ìˆ˜ì§‘

```bash
# 1. í™˜ê²½ ì„¤ì •
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. AWS ì•„ì´ì½˜ ë‹¤ìš´ë¡œë“œ
wget https://d1.awsstatic.com/webteam/architecture-icons/q1-2024/Asset-Package_01242024.7c4f8b8b.zip -O Asset-Package.zip

# 3. ë°ì´í„° ìˆ˜ì§‘ (ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ í¬í•¨)
python cli.py collect-data --data-type all --monitor --verbose
```

**ì˜ˆìƒ ì‹œê°„**: 5-10ë¶„ (ë„¤íŠ¸ì›Œí¬ ì†ë„ì— ë”°ë¼ ë‹¤ë¦„)

### Phase 2: CV ê¸°ë°˜ ë¶„ì„ í…ŒìŠ¤íŠ¸

```bash
# 1. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì¤€ë¹„
mkdir -p data/images
# AWS ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì„ data/images/ ë””ë ‰í„°ë¦¬ì— ë³µì‚¬

# 2. CV ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰
python cli.py analyze --input data/images/test_diagram.png --method cv --output data/outputs/experiments/cv_results --verbose

# 3. ê²°ê³¼ í™•ì¸
ls -la data/outputs/experiments/cv_results/
cat data/outputs/experiments/cv_results/analysis_result_000.json
```

**ì˜ˆìƒ ì‹œê°„**: 2-5ë¶„ (ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í¬í•¨)

### Phase 3: LLM ê¸°ë°˜ ë¶„ì„ (ì„ íƒì‚¬í•­)

```bash
# 1. OpenAI API í‚¤ ì„¤ì •
export OPENAI_API_KEY="your-api-key-here"

# 2. LLM ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰
python cli.py analyze --input data/images/test_diagram.png --method llm --output data/outputs/experiments/llm_results --verbose

# 3. ê²°ê³¼ í™•ì¸
ls -la data/outputs/experiments/llm_results/
cat data/outputs/experiments/llm_results/analysis_result_000.json
```

**ì˜ˆìƒ ì‹œê°„**: 1-3ë¶„ (API ì‘ë‹µ ì‹œê°„ì— ë”°ë¼ ë‹¤ë¦„)

### Phase 4: í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„

```bash
# 1. í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ ì‹¤í–‰ (CV + LLM ê²°í•©)
python cli.py analyze --input data/images/test_diagram.png --method hybrid --output data/outputs/experiments/hybrid_results --verbose

# 2. ê²°ê³¼ ë¹„êµ
ls -la data/outputs/experiments/
```

**ì˜ˆìƒ ì‹œê°„**: 3-8ë¶„ (CV + LLM ì²˜ë¦¬ ì‹œê°„)

### Phase 5: ì„±ëŠ¥ í‰ê°€ ë° ì‹œê°í™”

```bash
# 1. ë¶„ì„ ê²°ê³¼ ì‹œê°í™”
python cli.py visualize --input data/outputs/experiments/hybrid_results --output data/outputs/visualizations --verbose

# 2. ì„±ëŠ¥ í†µê³„ í™•ì¸
python cli.py status --method hybrid --verbose

# 3. ê²°ê³¼ íŒŒì¼ í™•ì¸
tree data/outputs/ -L 3
```

## ğŸ“ ì¶œë ¥ êµ¬ì¡°

## ğŸ¯ YOLO Classification í•™ìŠµ

AWS ì•„ì´ì½˜ ë¶„ë¥˜ë¥¼ ìœ„í•œ YOLO ëª¨ë¸ í•™ìŠµ ë° ì‚¬ìš© ë°©ë²•ì…ë‹ˆë‹¤.

### ë¹ ë¥¸ ì‹œì‘

```bash
# 1. í™˜ê²½ ì„¤ì •
conda activate archlens
./scripts/setup_yolo_env.sh

# 2. ë°ì´í„°ì…‹ ì¤€ë¹„ (ì•„ì§ ì•ˆ í–ˆë‹¤ë©´)
python scripts/prepare_yolo_dataset.py --mode fine

# 3. ëª¨ë¸ í•™ìŠµ
python scripts/train_yolo_cls.py --mode fine --epochs 100 --imgsz 256

# 4. ëª¨ë¸ í‰ê°€
python scripts/eval_yolo_cls.py \
    --model runs/classify/fine_cls_*/weights/best.pt \
    --mode fine \
    --split test

# 5. ì´ë¯¸ì§€ ì˜ˆì¸¡
# ë‹¨ì¼ ì´ë¯¸ì§€
python scripts/predict_yolo_cls.py \
    --model runs/classify/fine_cls_yolov8n-cls/weights/best.pt \
    --source "dataset/icons/images/fine/amazon s3/Arch_Amazon-S3_64.png" \
    --mode fine \
    --top-k 5

# ë””ë ‰í„°ë¦¬ ì „ì²´
python scripts/predict_yolo_cls.py \
    --model runs/classify/fine_cls_yolov8n-cls/weights/best.pt \
    --source "dataset/icons/images/fine/amazon s3" \
    --mode fine \
    --save-json \
    --save-txt
```

### ìƒì„¸ ê°€ì´ë“œ

## ğŸ“š ë¬¸ì„œ

í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ë¬¸ì„œëŠ” `docs/` ë””ë ‰í„°ë¦¬ì— ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

- **[ë¬¸ì„œ ì¸ë±ìŠ¤](docs/README.md)**: ì „ì²´ ë¬¸ì„œ ëª©ë¡ ë° êµ¬ì¡°
- **ê³„íš ë¬¸ì„œ** (`docs/01_plans/`): ë””ë ‰í„°ë¦¬ ì¬êµ¬ì„± ê³„íš
- **ì‚¬ìš© ê°€ì´ë“œ** (`docs/02_guides/`): 
  - [YOLO í•™ìŠµ ê°€ì´ë“œ](docs/02_guides/01_yolo_training_guide.md)
  - [ì¶”ë¡  ê°€ì´ë“œ](docs/02_guides/02_inference_guide.md)
- **ë¶„ì„ ë¬¸ì„œ** (`docs/03_analysis/`): í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„
- **ì°¸ê³  ìë£Œ** (`docs/04_reference/`): í”„ë¡œì íŠ¸ ê°œìš”, ëª¨ë“ˆ ë¹„êµ, ê¸°ìˆ  ìš©ì–´ì§‘ ë“±

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ”— ê´€ë ¨ ë§í¬

- [AWS ê³µì‹ ì•„ì´ì½˜](https://aws.amazon.com/ko/architecture/icons/)
- [OpenAI API ë¬¸ì„œ](https://platform.openai.com/docs/)
- [CLIP ëª¨ë¸](https://github.com/openai/CLIP)
- [OpenCLIP](https://github.com/mlfoundations/open_clip)

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

---

```
conda create -n archlens python=3.11 -y
conda activate archlens
which python ; which python3 ; which pip ; which pip3
conda install ipykernel -y
python -m ipykernel install --user --name archlens --display-name "(archlens)"
jupyter kernelspec list | grep archlens
pip install pandas jupyterlab ipython
pip install -r requirements.txt

```